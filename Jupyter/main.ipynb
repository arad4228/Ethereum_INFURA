{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import threading\n",
    "import pandas as pd\n",
    "from web3 import Web3\n",
    "from pprint import pprint as pp\n",
    "from secrete import *\n",
    "\n",
    "# 여러개의 CSV를 처리하기 위해서 사용\n",
    "from multiprocessing import Process, Pool\n",
    "# 한 CSV에서 탐색하기 위해서 사용\n",
    "from threading import Thread, Lock\n",
    "\n",
    "base_URL = \"https://mainnet.infura.io/v3/\"\n",
    "base_Input_PATH = \"./input/\"\n",
    "base_Output_PATH = \"./output/\"\n",
    "\n",
    "MAX_Chunk_Number = 362\n",
    "MAX_Quiry = 100000\n",
    "MAX_Thread_Quiry = 20000\n",
    "\n",
    "INFURA_URL_Limit_List = {key: 0 for key in INFURA_URL_List}\n",
    "Second_INFURA_URL_Limit_List = {key: 0 for key in Second_INFURA_URL_List}\n",
    "used_urls = set()\n",
    "lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_eoa(w3, address):\n",
    "    try:\n",
    "        checksum_address = w3.to_checksum_address(address)\n",
    "        uri = (w3.provider.endpoint_uri).replace(base_URL,\"\")\n",
    "        INFURA_URL_Limit_List[uri] += 1\n",
    "        return w3.eth.get_code(checksum_address) == b''\n",
    "    except Exception as e:\n",
    "        Exception(f\"{uri} key is expired\")\n",
    "        \n",
    "\n",
    "def find_available_url():\n",
    "    with lock:\n",
    "        for url in INFURA_URL_List:\n",
    "            if url not in used_urls and MAX_Quiry - INFURA_URL_Limit_List[url] >= MAX_Thread_Quiry and INFURA_URL_Limit_List[url] < MAX_Quiry:\n",
    "                used_urls.add(url)\n",
    "                return url\n",
    "\n",
    "        for url in Second_INFURA_URL_List:\n",
    "            if url not in used_urls and MAX_Quiry - Second_INFURA_URL_Limit_List[url] >= MAX_Thread_Quiry and Second_INFURA_URL_Limit_List[url] < MAX_Quiry:\n",
    "                used_urls.add(url)\n",
    "                return url\n",
    "\n",
    "        raise Exception(\"All API Keys expired or reached limit\")\n",
    "\n",
    "\n",
    "def work_thread(chunk_df, return_df):\n",
    "    url_INFURA = find_available_url()\n",
    "    w3 = Web3(Web3.HTTPProvider(base_URL + url_INFURA))\n",
    "    print(f\"{threading.current_thread().name} Start\")\n",
    "    print(f\"Using API-Key:{url_INFURA}\")\n",
    "\n",
    "    # Convert the addresses to checksum format after handling NaN values\n",
    "    chunk_df['from_address'] = chunk_df['from_address'].apply(w3.to_checksum_address)\n",
    "    chunk_df['to_address'] = chunk_df['to_address'].apply(w3.to_checksum_address)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            eoa_df = chunk_df[\n",
    "                (chunk_df['from_address'].apply(lambda x: is_eoa(w3, x))) & \n",
    "                (chunk_df['to_address'].apply(lambda x: is_eoa(w3, x)))\n",
    "            ]\n",
    "            return_df.append(eoa_df)\n",
    "            # 다 사용했다면, 회수하기.\n",
    "            used_urls.remove(url_INFURA)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if e in \"All API Keys\":\n",
    "                raise Exception(\"All API Keys expired or reached limit\")\n",
    "            else:\n",
    "                url_INFURA = find_available_url\n",
    "                print(f'Change the API Key to {url_INFURA}')\n",
    "                w3 = Web3(Web3.HTTPProvider(base_URL + url_INFURA))\n",
    "\n",
    "\n",
    "def refine_INFURA(nProcess: str, file_Name: str):\n",
    "    print(f\"Process{nProcess} start reading {file_Name}\")\n",
    "    # 1 process 4 INFURA_URL\n",
    "    file_Path = base_Input_PATH+file_Name\n",
    "    chunk_df = pd.read_csv(file_Path)\n",
    "\n",
    "    #chunk_df = pd.read_csv(\"C:\\\\Users\\\\PET\\\\Desktop\\\\논문작성관련\\\\self-trade\\\\230914\\\\result_1.csv\")\n",
    "    # Drop rows with NaN or empty values in 'from_address' or 'to_address'\n",
    "    chunk_df = chunk_df.dropna(subset=['from_address', 'to_address'])\n",
    "    thread_List = []\n",
    "    output_df_list = []\n",
    "\n",
    "    addition_Count = 10000\n",
    "    start = 0\n",
    "\n",
    "    for nThread in range(4):\n",
    "        end = start + addition_Count\n",
    "       \n",
    "        # check API key limitation\n",
    "        all_limits_exceeded = all(INFURA_URL_Limit_List[url] >= 100000 for url in INFURA_URL_List)\n",
    "        if all_limits_exceeded:\n",
    "            raise Exception(\"All API Key expired\")\n",
    "\n",
    "        thread_List.append(Thread(target=work_thread, args=(chunk_df.loc[start: end], output_df_list)))\n",
    "        start += addition_Count\n",
    "\n",
    "        try:\n",
    "            thread_List[nThread].start()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"All API Key expired\\nLast FileName: {file_Name}\")\n",
    "\n",
    "    print(f\"All Thread Started at {datetime.datetime.now()}\")\n",
    "\n",
    "    for thread in thread_List:\n",
    "        thread.join()\n",
    "    print(\"Thread End\")\n",
    "    # 사용했던 기록은 제거\n",
    "\n",
    "    print(\"All Thread Complete\")\n",
    "    eoa_df = output_df_list[0]\n",
    "    for i in range(1, 4):\n",
    "        eoa_df = pd.concat([eoa_df, output_df_list[i]])\n",
    "\n",
    "    # Save the filtered dataframe to result_1.csv\n",
    "    now = datetime.datetime.now().strftime(\"%Y.%m.%d\")\n",
    "    eoa_df.to_csv(f\"{base_Output_PATH}reulst_{file_Name}({now}).csv\", index=False)\n",
    "\n",
    "    print(f\"Process{nProcess} Done\\nOutput: reulst_{file_Name}({now}).csv\")\n",
    "    pp(INFURA_URL_Limit_List)\n",
    "    pp(Second_INFURA_URL_Limit_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pool Version\n",
    "미완"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter version\n",
    "if __name__ == \"__main__\":\n",
    "    nProcess = 2\n",
    "    p = Pool(proces=nProcess)\n",
    "    \n",
    "        try:\n",
    "\n",
    "               \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        for process in Process_List:\n",
    "            process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py version\n",
    "if __name__ == \"__main__\":\n",
    "    Process_List = []\n",
    "    for i in range(2, MAX_Chunk_Number,2):\n",
    "        try:\n",
    "            for nProcess in range(2):\n",
    "                process = str(nProcess+1)\n",
    "                file_name = \"chunk_\"+str(i+nProcess)\n",
    "                p = Process(target=refine_INFURA, args=(process, file_name))\n",
    "                p.start()\n",
    "                Process_List.append(p)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        for process in Process_List:\n",
    "            process.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
